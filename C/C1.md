# 主成分分析 (PCA - Principal Component Analysis)

## 模型简介

主成分分析是一种降维技术，通过线性变换将高维数据投影到低维空间，同时最大化保留数据的方差信息。PCA能够消除变量间的相关性，提取数据的主要特征。

## 适用场景

### 数学建模竞赛中的典型应用

1. **数据降维** - 高维特征压缩为低维表示
2. **特征提取** - 从原始变量中提取主要信息
3. **数据可视化** - 高维数据的2D/3D可视化
4. **噪声过滤** - 去除数据中的噪声成分
5. **综合评价** - 构建综合评价指标体系
6. **图像压缩** - 图像数据的压缩存储
7. **质量控制** - 多指标质量评估体系
8. **市场分析** - 消费者行为模式分析

### 典型问题特征

- 变量维数较高（通常>10个变量）
- 变量间存在相关性或共线性
- 需要降维但要保持数据主要信息
- 希望消除变量间的相关性

## 算法原理

### 数学基础

1. **标准化**: 将数据标准化为均值0方差1
2. **协方差矩阵**: 计算变量间的协方差矩阵
3. **特征分解**: 求协方差矩阵的特征值和特征向量
4. **主成分选择**: 按特征值大小排序，选择前k个主成分
5. **数据变换**: 将原数据投影到主成分空间

### 关键概念

- **特征值**: 表示主成分的方差大小
- **特征向量**: 表示主成分的方向
- **贡献率**: 各主成分解释的方差比例
- **累计贡献率**: 前k个主成分的总贡献率

## 使用方法

### 1. 基本调用

```python
from M_C1_PCA import *
import numpy as np
import pandas as pd

# 加载数据 (样本×特征)
data = pd.read_csv('your_data.csv')
X = data.values

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 应用PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# 查看结果
print("降维后数据形状:", X_pca.shape)
print("方差贡献率:", pca.explained_variance_ratio_)
print("累计贡献率:", np.cumsum(pca.explained_variance_ratio_))
```

### 2. 参数说明

**n_components**:
- 整数: 保留的主成分个数
- 小数: 保留的方差比例 (如0.95表示保留95%方差)
- 'mle': 使用MLE估计最佳成分数
- None: 保留所有成分

### 3. 主成分个数选择

```python
# 方法1: 累计贡献率法
pca_full = PCA()
pca_full.fit(X_scaled)
cumsum = np.cumsum(pca_full.explained_variance_ratio_)
n_components = np.argmax(cumsum >= 0.85) + 1  # 保留85%方差

# 方法2: 碎石图法
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(cumsum)+1), cumsum, 'bo-')
plt.axhline(y=0.85, color='r', linestyle='--')
plt.xlabel('主成分个数')
plt.ylabel('累计方差贡献率')
plt.title('碎石图')
plt.show()

# 方法3: Kaiser准则（特征值>1）
eigenvalues = pca_full.explained_variance_
n_components = sum(eigenvalues > 1)
```

### 4. 结果解释

```python
# 主成分载荷矩阵（原变量在主成分上的系数）
loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
loadings_df = pd.DataFrame(
    loadings,
    columns=[f'PC{i+1}' for i in range(pca.n_components_)],
    index=data.columns
)
print("主成分载荷矩阵:")
print(loadings_df)

# 主成分得分（样本在主成分上的取值）
scores_df = pd.DataFrame(
    X_pca,
    columns=[f'PC{i+1}' for i in range(pca.n_components_)]
)
```

## 注意事项

### 数据预处理

1. **标准化必须**: 不同量纲的变量必须标准化
2. **缺失值处理**: PCA不能处理缺失值，需事先填充
3. **异常值影响**: 异常值对结果影响较大，建议预处理

### 结果解释

1. **主成分意义**: 需要根据载荷矩阵解释主成分的实际含义
2. **符号任意性**: 主成分方向的正负号是任意的
3. **样本量要求**: 样本数应大于变量数，理想比例为5:1以上

### 适用条件

1. **线性关系**: PCA假设变量间为线性关系
2. **连续变量**: 主要适用于连续型变量
3. **相关性**: 变量间应存在相关性，否则降维意义不大

## 代码文件

- **文件名**: `M_C1_PCA.py`
- **主要库**: `sklearn.decomposition.PCA`
- **示例**: 虚拟数据集的PCA降维与可视化

## 扩展应用

### 高级技术

1. **核PCA**: 处理非线性关系
2. **稀疏PCA**: 产生稀疏的主成分载荷
3. **增量PCA**: 处理大规模数据集
4. **概率PCA**: 带有概率解释的PCA

### 相关方法

1. **因子分析**: 更适合探索潜在因子结构
2. **独立成分分析(ICA)**: 寻找统计独立的成分
3. **t-SNE**: 非线性降维，适合可视化
4. **UMAP**: 保持局部和全局结构的降维

### 实际应用技巧

1. **特征工程**: PCA后的主成分可作为新特征
2. **异常检测**: 利用重构误差检测异常
3. **压缩存储**: 降维后数据的存储和传输
4. **预处理步骤**: 作为其他机器学习算法的预处理