# C5: 多元回归分析 (Multiple Regression Analysis)

## 算法简介

多元回归分析是统计学中分析多个自变量与因变量之间关系的经典方法。它通过建立线性或非线性的数学模型，揭示变量间的定量关系，并可用于预测和解释。

## 数学原理

### 线性回归模型
$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \varepsilon$$

其中：
- $y$：因变量（响应变量）
- $x_1, x_2, ..., x_p$：自变量（预测变量）
- $\beta_0, \beta_1, ..., \beta_p$：回归系数
- $\varepsilon$：误差项

### 正则化回归
- **Ridge回归**：L2正则化，$\min ||y - X\beta||^2 + \alpha||\beta||^2$
- **Lasso回归**：L1正则化，$\min ||y - X\beta||^2 + \alpha||\beta||_1$

## CUMCM竞赛中的应用场景

### A类问题应用
- **物理建模**：建立物理量之间的经验关系
- **工程优化**：分析设计参数对性能的影响

### B类问题应用
- **需求预测**：基于历史数据预测未来需求
- **成本分析**：分析各因素对总成本的贡献

### C类问题应用（重点）
- **影响因素分析**：识别对结果影响显著的变量
- **预测建模**：建立预测模型进行定量预测
- **政策评估**：分析政策变量对目标的影响
- **质量控制**：找出影响产品质量的关键因素
- **市场分析**：分析市场因素对销售的影响

## 算法优势

### 1. 可解释性强
- 回归系数直接反映变量影响程度
- 统计显著性检验明确
- 置信区间提供不确定性量化

### 2. 理论基础扎实
- 有完整的统计推断理论
- 模型假设明确，可验证
- 诊断方法丰富

### 3. 应用广泛
- 适用于连续型结果变量
- 可扩展到非线性关系（多项式回归）
- 与其他方法结合使用

## 回归方法对比

### 1. 普通最小二乘法(OLS)
- **优点**：无偏估计，计算简单
- **缺点**：对多重共线性敏感
- **适用**：特征相对独立，样本充足

### 2. Ridge回归
- **优点**：处理多重共线性，估计稳定
- **缺点**：不进行特征选择
- **适用**：特征间存在相关性

### 3. Lasso回归
- **优点**：自动特征选择，模型稀疏
- **缺点**：可能选择相关特征中的任意一个
- **适用**：高维数据，需要特征选择

## 模型诊断

### 1. 回归假设检验
- **线性性**：残差图检验
- **独立性**：DW检验
- **正态性**：Q-Q图、Shapiro-Wilk检验
- **等方差性**：Breusch-Pagan检验

### 2. 多重共线性检验
- **方差膨胀因子(VIF)**：VIF > 10表示共线性严重
- **相关性矩阵**：特征间相关系数分析
- **条件数**：设计矩阵的条件数

### 3. 异常值检测
- **标准化残差**：|标准化残差| > 2为异常
- **Cook距离**：影响较大的观测值
- **杠杆值**：在自变量空间中的异常点

## 评估指标

### 1. 拟合优度
- **R²**：解释变异的比例，越接近1越好
- **调整R²**：考虑变量数量的修正R²
- **AIC/BIC**：信息准则，用于模型选择

### 2. 预测精度
- **均方误差(MSE)**：预测误差的平方均值
- **均方根误差(RMSE)**：MSE的平方根，与y同单位
- **平均绝对误差(MAE)**：预测误差绝对值的均值

### 3. 统计显著性
- **t检验**：单个系数的显著性
- **F检验**：整体模型的显著性
- **p值**：显著性水平的度量

## 特征工程技巧

### 1. 多项式特征
```python
# 添加平方项和交互项
X_poly = PolynomialFeatures(degree=2).fit_transform(X)
```

### 2. 数据预处理
```python
# 标准化处理
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 3. 特征变换
```python
# 对数变换处理偏度
y_log = np.log(y + 1)

# Box-Cox变换
from scipy import stats
y_boxcox, lambda_opt = stats.boxcox(y + 1)
```

## 常见问题及解决

### 1. 多重共线性
- **问题**：特征间高度相关，系数估计不稳定
- **解决**：使用Ridge回归，或删除相关特征

### 2. 异方差性
- **问题**：误差方差不恒定
- **解决**：加权最小二乘法，或变量变换

### 3. 非线性关系
- **问题**：变量间关系非线性
- **解决**：多项式回归，或样条回归

### 4. 特征选择
- **问题**：特征过多，模型复杂
- **解决**：使用Lasso回归自动选择特征

## 实战建模流程

### 1. 探索性数据分析
```python
# 查看变量分布
import matplotlib.pyplot as plt
import seaborn as sns

# 相关性热力图
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True)
```

### 2. 模型建立
```python
from M_C5_MultipleRegression import multiple_regression

# 基础回归
model, results = multiple_regression(X, y, method='ols')

# 特征选择回归
model_lasso, features, results_lasso = feature_selection_regression(X, y, feature_names)
```

### 3. 模型验证
```python
# 残差分析
residuals = y_test - y_pred
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
```

### 4. 结果解释
```python
# 系数解释
for name, coef in zip(feature_names, model.coef_):
    print(f"{name}: 增加1单位，y变化{coef:.3f}")
```

## 高级应用

### 1. 分层回归
- 逐步添加变量组
- 比较模型解释力增量
- 控制变量的影响

### 2. 交互效应分析
```python
# 添加交互项
X['interaction'] = X['var1'] * X['var2']
```

### 3. 中介效应分析
- Baron & Kenny方法
- Bootstrap置信区间
- Sobel检验

### 4. 调节效应分析
- 分组回归比较
- 交互项显著性检验
- 简单斜率分析

---

*多元回归是数据分析的核心工具，掌握其原理和应用对CUMCM数据分析问题至关重要。*