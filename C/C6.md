# C6: 聚类分析 (Cluster Analysis)

## 算法简介

聚类分析是一种无监督学习方法，旨在将数据集中的样本根据相似性分成若干个组别（簇）。同一簇内的样本相似度高，不同簇间的样本差异度大。

## 核心概念

### 相似性度量
- **欧氏距离**：$d(x,y) = \sqrt{\sum(x_i - y_i)^2}$
- **曼哈顿距离**：$d(x,y) = \sum|x_i - y_i|$
- **余弦相似度**：$sim(x,y) = \frac{x \cdot y}{||x|| \cdot ||y||}$

### 聚类质量评估
- **轮廓系数**：衡量样本与其簇的拟合程度
- **Calinski-Harabasz指数**：类间离散度与类内离散度比值
- **类内平方和(WSS)**：簇内紧密程度

## CUMCM竞赛中的应用场景

### A类问题应用
- **信号分类**：将相似的信号模式归类
- **状态识别**：识别系统的不同工作状态

### B类问题应用
- **路径聚类**：相似路径的归类分析
- **策略分组**：将相似的优化策略分类

### C类问题应用（重点）
- **客户细分**：根据消费行为将客户分类
- **市场分割**：识别不同的细分市场
- **产品分类**：根据属性将产品归类
- **区域划分**：基于特征将地理区域分组
- **用户画像**：构建不同类型的用户群体
- **异常检测**：识别偏离正常模式的数据点

## 聚类算法对比

### 1. K-means聚类
- **原理**：基于距离的划分聚类
- **优点**：简单高效，适合球形簇
- **缺点**：需预设簇数，对异常值敏感
- **适用**：数据分布较均匀，簇大小相似

### 2. 层次聚类
- **原理**：构建层次化的聚类树
- **优点**：不需预设簇数，结果直观
- **缺点**：计算复杂度高，对噪声敏感
- **适用**：探索性分析，需要层次结构

### 3. DBSCAN密度聚类
- **原理**：基于密度连接的聚类
- **优点**：可发现任意形状簇，自动识别噪声
- **缺点**：参数选择较困难
- **适用**：簇密度不均匀，存在噪声数据

## 最优簇数确定

### 1. 肘部法则(Elbow Method)
```python
# 计算不同k值的WSS
wss = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X)
    wss.append(kmeans.inertia_)

# 寻找"肘部"拐点
```

### 2. 轮廓系数法
```python
# 计算不同k值的轮廓系数
silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    silhouette_scores.append(score)

# 选择最高轮廓系数对应的k
```

### 3. Gap统计量
- 比较实际数据和随机数据的聚类效果
- 选择Gap统计量最大的k值

## 数据预处理

### 1. 标准化处理
```python
from sklearn.preprocessing import StandardScaler

# 消除量纲影响
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 2. 降维处理
```python
from sklearn.decomposition import PCA

# 高维数据降维
pca = PCA(n_components=0.95)  # 保留95%方差
X_reduced = pca.fit_transform(X_scaled)
```

### 3. 异常值处理
```python
# 使用箱线图法去除异常值
Q1 = X.quantile(0.25)
Q3 = X.quantile(0.75)
IQR = Q3 - Q1
X_clean = X[~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)]
```

## 聚类结果分析

### 1. 簇特征分析
```python
# 计算各簇的统计特征
cluster_stats = []
for i in range(n_clusters):
    cluster_data = X[labels == i]
    stats = {
        '簇大小': len(cluster_data),
        '特征均值': cluster_data.mean(),
        '特征标准差': cluster_data.std()
    }
    cluster_stats.append(stats)
```

### 2. 簇间差异分析
- 计算簇中心间的距离
- 分析不同簇在各维度上的差异
- 识别区分簇的关键特征

### 3. 业务解释
- 为每个簇命名和解释
- 分析簇的实际业务意义
- 提出针对性的策略建议

## 常见应用模式

### 1. 客户细分案例
```python
# 特征：消费金额、频次、最近购买时间
features = ['消费金额', '购买频次', '最近购买']
X = customer_data[features]

# 聚类分析
labels, centers, results = kmeans_clustering(X, n_clusters=4)

# 结果解释
# 簇1: 高价值客户（高金额、高频次）
# 簇2: 活跃客户（中等金额、高频次）
# 簇3: 潜在客户（低金额、中等频次）
# 簇4: 流失客户（低金额、低频次）
```

### 2. 市场分析案例
```python
# 特征：产品特性、价格、市场份额
features = ['质量评分', '价格水平', '品牌知名度', '市场份额']

# 分析竞争格局
optimal_k, scores = optimal_clusters(X, method='silhouette')
labels, centers, results = kmeans_clustering(X, n_clusters=optimal_k)
```

## 可视化技巧

### 1. 二维聚类图
```python
import matplotlib.pyplot as plt

# PCA降维到2维
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X)

# 绘制聚类结果
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels)
plt.scatter(centers_2d[:, 0], centers_2d[:, 1], marker='x', s=200, c='red')
```

### 2. 树状图（层次聚类）
```python
from scipy.cluster.hierarchy import dendrogram, linkage

# 绘制聚类树
linkage_matrix = linkage(X, method='ward')
dendrogram(linkage_matrix)
```

### 3. 轮廓图
```python
from sklearn.metrics import silhouette_samples

# 绘制轮廓系数分布
silhouette_vals = silhouette_samples(X, labels)
plt.barh(range(len(X)), sorted(silhouette_vals))
```

## 实战技巧

### 1. 参数选择
- K-means：用肘部法和轮廓系数确定k值
- DBSCAN：根据k-distance图选择eps参数
- 层次聚类：根据树状图选择切割位置

### 2. 结果验证
- 交叉验证聚类稳定性
- 对比不同算法的结果
- 业务专家验证聚类合理性

### 3. 聚类后分析
- 为每个簇制定特定策略
- 分析簇随时间的变化
- 预测新样本的簇归属

## 扩展应用

### 1. 半监督聚类
- 结合少量标签信息
- 约束聚类方法

### 2. 在线聚类
- 处理流数据的增量聚类
- 自适应调整簇结构

### 3. 多视图聚类
- 整合多种特征视角
- 共识聚类方法

---

*聚类分析是数据挖掘的重要工具，在CUMCM数据分析问题中能够揭示数据的内在结构和模式。*