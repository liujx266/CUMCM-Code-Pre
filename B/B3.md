# 粒子群优化算法 (Particle Swarm Optimization, PSO)

## 模型简介

粒子群优化算法是一种基于群体智能的启发式优化算法，模拟鸟群觅食行为。每个粒子代表解空间中的一个潜在解，通过粒子间的信息共享和协作来寻找全局最优解。PSO算法具有参数少、收敛快、易实现等优点。

## 适用场景

### 数学建模竞赛中的典型应用

1. **连续函数优化** - 非线性函数的全局最优解
2. **参数估计与拟合** - 模型参数优化、曲线拟合
3. **工程设计优化** - 结构参数、系统参数优化
4. **神经网络训练** - 权重和阈值优化
5. **投资组合优化** - 资产配置、风险控制
6. **路径规划** - 最短路径、避障路径
7. **资源调度** - 任务分配、生产调度
8. **图像处理** - 特征选择、参数调优

### 典型问题特征

- 连续优化问题（实数编码）
- 多维、多峰、非线性目标函数
- 需要快速收敛的优化问题
- 对初值不敏感的全局搜索
- 约束条件相对简单的问题

## 算法原理

### 核心思想

每个粒子在解空间中飞行，根据以下三个因素调整飞行方向：
1. **惯性**: 保持当前飞行方向
2. **认知**: 向个体历史最优位置飞行
3. **社会**: 向群体全局最优位置飞行

### 数学模型

**速度更新公式**：
```
v_{i}^{t+1} = w·v_{i}^{t} + c1·r1·(pbest_i - x_{i}^{t}) + c2·r2·(gbest - x_{i}^{t})
```

**位置更新公式**：
```
x_{i}^{t+1} = x_{i}^{t} + v_{i}^{t+1}
```

**参数说明**：
- `w`: 惯性权重，控制前一代速度的影响
- `c1`: 个体学习因子，控制向个体最优的趋近程度
- `c2`: 社会学习因子，控制向全局最优的趋近程度
- `r1, r2`: [0,1]区间随机数，增加随机性
- `pbest_i`: 粒子i的个体最优位置
- `gbest`: 群体全局最优位置

## 使用方法

### 1. 标准PSO调用

```python
from M_B3_ParticleSwarmOptimization import particle_swarm_optimization
import numpy as np

# 定义目标函数 (最小化问题)
def objective(x):
    return x[0]**2 + x[1]**2  # 简单二次函数

# 设置参数
bounds = [[-10, 10], [-10, 10]]  # 变量范围
n_particles = 30                 # 粒子数量
n_iter = 100                     # 迭代次数
w = 0.5                          # 惯性权重
c1 = 2.0                         # 个体学习因子
c2 = 2.0                         # 社会学习因子

# 运行PSO算法
best_pos, best_fit, history = particle_swarm_optimization(
    objective, bounds, n_particles, n_iter, w, c1, c2, minimize=True
)

print(f"最优解: {best_pos}")
print(f"最优值: {best_fit}")
```

### 2. 自适应PSO调用

```python
from M_B3_ParticleSwarmOptimization import adaptive_pso

# 使用自适应惯性权重的PSO
best_pos, best_fit, history = adaptive_pso(
    objective, bounds, n_particles, n_iter, 
    w_max=0.9, w_min=0.4, c1=2.0, c2=2.0, minimize=True
)
```

### 3. 参数说明

**必需参数**：
- **objective_func**: 目标函数 f(x)，输入数组，输出标量
- **bounds**: 变量取值范围 [[min1,max1], [min2,max2], ...]
- **n_particles**: 粒子群大小
- **n_iter**: 最大迭代次数

**可选参数**：
- **w**: 惯性权重 (默认0.5)
- **c1**: 个体学习因子 (默认2.0)
- **c2**: 社会学习因子 (默认2.0)
- **minimize**: True为最小化，False为最大化 (默认True)

**自适应PSO额外参数**：
- **w_max**: 最大惯性权重 (默认0.9)
- **w_min**: 最小惯性权重 (默认0.4)

### 4. 参数调优建议

**粒子群大小**：
- 低维问题: 20-40个粒子
- 高维问题: 40-100个粒子
- 复杂多峰问题: 可增加到100-200个粒子

**惯性权重**：
- 大w值: 全局搜索能力强，收敛慢
- 小w值: 局部搜索能力强，收敛快
- 推荐: 0.4-0.9 或自适应递减

**学习因子**：
- c1=c2=2.0 (经典设置)
- c1>c2: 重视个体经验
- c1<c2: 重视群体经验
- 推荐范围: 1.5-2.5

**迭代次数**：
- 根据收敛曲线判断
- 简单问题: 50-200代
- 复杂问题: 200-1000代

## 算法特点

### 优点
1. **参数少**: 只需调整w、c1、c2三个主要参数
2. **收敛快**: 通常比遗传算法收敛更快
3. **易实现**: 算法简单，编程容易
4. **全局搜索**: 具有较好的全局优化能力
5. **鲁棒性**: 对参数变化不太敏感

### 缺点
1. **易早熟收敛**: 可能陷入局部最优
2. **精度有限**: 后期收敛精度可能不高
3. **参数依赖**: 性能依赖于参数选择
4. **连续问题**: 主要适用于连续优化

## 改进策略

### 1. 惯性权重策略
- **线性递减**: w从0.9线性递减到0.4
- **非线性递减**: 指数或对数递减
- **自适应**: 根据适应度变化调整

### 2. 拓扑结构
- **全连接**: 所有粒子共享信息
- **环形**: 粒子只与邻居交流
- **星形**: 通过中心粒子交流

### 3. 多样性保持
- **变异操作**: 随机扰动粒子位置
- **重新初始化**: 停滞时重新初始化部分粒子
- **多群策略**: 多个子群并行搜索

### 4. 混合策略
- **PSO+局部搜索**: 结合梯度下降等局部方法
- **PSO+遗传算法**: 优势互补
- **多目标PSO**: 处理多目标优化

## 经典测试函数

### 1. Sphere函数 (单峰)
```python
def sphere(x):
    return np.sum(x**2)
# 全局最优: f(0,0,...,0) = 0
```

### 2. Rastrigin函数 (多峰)
```python
def rastrigin(x):
    A = 10
    n = len(x)
    return A*n + np.sum(x**2 - A*np.cos(2*np.pi*x))
# 全局最优: f(0,0,...,0) = 0
```

### 3. Ackley函数 (多峰)
```python
def ackley(x):
    n = len(x)
    sum1 = np.sum(x**2)
    sum2 = np.sum(np.cos(2*np.pi*x))
    return -20*np.exp(-0.2*np.sqrt(sum1/n)) - np.exp(sum2/n) + 20 + np.e
# 全局最优: f(0,0,...,0) = 0
```

## 应用实例

### 示例1：函数优化
```python
# 优化 f(x,y) = (x-1)^2 + (y-2)^2，理论最优解为(1,2)
def func(x):
    return (x[0]-1)**2 + (x[1]-2)**2

bounds = [[-5, 5], [-5, 5]]
best_pos, best_fit, _ = particle_swarm_optimization(
    func, bounds, 30, 100, minimize=True
)
```

### 示例2：参数拟合
```python
# 拟合数据到模型 y = a*x^2 + b*x + c
import numpy as np

# 生成测试数据
x_data = np.linspace(0, 10, 50)
y_data = 2*x_data**2 + 3*x_data + 1 + np.random.normal(0, 0.1, 50)

def fitting_error(params):
    a, b, c = params
    y_pred = a*x_data**2 + b*x_data + c
    return np.mean((y_data - y_pred)**2)  # MSE

bounds = [[-10, 10], [-10, 10], [-10, 10]]  # a, b, c的范围
best_params, mse, _ = particle_swarm_optimization(
    fitting_error, bounds, 30, 200, minimize=True
)

print(f"拟合参数: a={best_params[0]:.3f}, b={best_params[1]:.3f}, c={best_params[2]:.3f}")
```

## 注意事项

1. **目标函数**: 确保函数计算稳定，避免数值异常
2. **边界处理**: 代码已实现反弹策略，也可选择其他策略
3. **收敛判断**: 可设置容忍度或最大停滞代数提前停止
4. **多次运行**: PSO是随机算法，建议多次运行取最好结果
5. **问题规模**: 高维问题可能需要增加粒子数和迭代次数

## 代码文件

- **文件名**: `M_B3_ParticleSwarmOptimization.py`
- **主函数**: 
  - `particle_swarm_optimization()`: 标准PSO算法
  - `adaptive_pso()`: 自适应惯性权重PSO
- **示例**: Sphere和Rastrigin函数优化，包含可视化

## 扩展阅读

### 理论基础
- Kennedy J, Eberhart R. Particle swarm optimization[C]. ICNN'95, 1995.
- Shi Y, Eberhart R. A modified particle swarm optimizer[C]. IEEE CEC, 1998.

### 高级变种
- **SPSO**: Standard Particle Swarm Optimization
- **CLPSO**: Comprehensive Learning PSO
- **MOPSO**: Multi-Objective PSO
- **QPSO**: Quantum-behaved PSO